---
title: "Rating Assignment Methodologies"
layout: post
---
The assessment of default risk and the assignment of ratings of quantifying credit risk.

# Ratings Systems
_LO 20a: Explain the key features of a good ratings system_

* Objectivity and Homogeneity - it will produce judgements solely based on Credit Risk
* Specificity - it will measure the distance to default while ignoring other financial elements
* Measurability and Verifiability - the expectations are correct and can be verified using backtesting

_LO 20b: Describe the experts-based approaches, statistical-based models, and numerical approaches to predicting default_

Expert-based systems such as CAMELS, LAPS and others, combine several qualitative features with quantitative metrics to arrive at a credit rating, whereas quantitative methods purely focus on the statistical reality of a credit. 

_LO 20c: Describe a rating migration matrix and calculate the probability of default, cumulative probability of default, marginal probability of default, and annualised default rate_

Credit rating migrations are path-dependant probabilities on how likely a credit is to change from one rating to another. There is…

Proability of Default (PD), which is…

$$PD_k = \frac{defaulted_{t}^{t+k}}{names_t}$$

where: 
PD = probability of default
defaulted = number of issuer names that have defaulted in the applicable time horizon
names = number of issuers
k = time horizon

The Cumulative Probability of Default (CPD) can be calculated as…

$$PD_k^{cumulaitve} = \frac{\sum^{i=t+k}_{i=t}defauled_i}{names_t}$$

The marginal probability of default then can be calculated as…

$$PD_k^{marginal} = PD^{cumulative}_{t+k} - PD^{cumulative}_k$$

Finally, the annualised default rate (ADR) can be calculated by…

discrete ADR: $$ADR_t = 1 - \sqrt[t]{(1-PD_t^{cumulaitve})}$$

cumulative ADR: $$ADR_t = -\frac{ln(1-PD_t^{cumulative})}{t}$$

## Ratings Agencies' Methodologies
_LO 20d Describe rating agencies' assignment methodologies for issue and issuer ratings_

Each ratings agency will have an in-house process which makes use of inside-information, engagement with management, and quantitative analysis. Moody's focuses on ratings for actual issuances; S&P focuses on ratings for issuers. FItch focuses on issuer ratings for publicly listed bonds. 

## Borrower Rating and Probability of Default
_LO 20e: Describe the relationship between borrower rating and probability of default_

In line with intuitive expectations, and in line with the law of large numbers, generally the highest rated issuances are observed to rarely ever default, even over a 10 year period, whereas the lowest are almost gauranteed to default early in a 10-year period. 

## Agencies' Ratings vs. Experts-Based Approaches
_LO 20f: Compare agencies' ratings to internal experts-based ratings systems_

In line with the ideal factors identified earlier in the post…

* Objectivity and Homogeneity: Agencies are 75% compliant, internal experts-based systems are 50% compliant
* Specificity: Agencies are 100% compliant, internal experts-based systems are 75% compliant
* Measurability and Verifiability: Agencies are 75% compliant, internal experts-based systems are 25% compliant

# Structural and Reduced Form Approaches
_LO 20g: Distinguish between the structural approaches and the reduced-form approaches to predicting default_

The foundation of a structural approach is the financial and economic theoretical assumptions that describe the overall path to default. Reduced form models arrive at a solution using the set of variables that is most statistically suitable without factoring in theoretical or conceptual causal relationships. 

## Merton Model
_LO 20h: Apply the Merton model to calculate default probability and the distance to default and describe the limitations of using the Merton model_

The Merton model is a structural approach to implies that default happens when the underlying structure of the entity is no longer worthwhile. In Merton, the equity of the firm represents a call option on the market value of the assets. As such the value of equity is a by-product of the market value and volatility of assets, as well as the book value of liabilities. The Black-Scholes-Merton formula is: 

$PD = N(\frac{ln(F) - ln(V_A) - \mu T + \frac{1}{2} \sigma^2_A T}{\sigma_A \sqrt{T}})$

where: 
ln = the natural logarithm
F = debt face value
$$V_A$$ = firm asset value (market value of equity and net debt)
$$\mu$$ = expected return in the "risky world"
T = time to maturity remaining
$$\sigma_A$$ = volatility (standard deviation of asset values)
N = cumulative normal distribution operator

The values inside the parenthesis are the "Distance to Debt" value - the Distance to Default is: 

$DtD = \frac{ln(V_A) - ln(F) + (\mu_{risky}-\frac{\sigma^2_A}{2})-{"other\space payouts"}}{\sigma_A} \cong \frac{ln V - ln F}{\sigma_A}$

## Linear Discriminant Analysis
_LO 20i: Describe linear discriminant analysis (LDA), define the Z-score and its usage and apply LDA to classify a sample of firms by credit quality_

LDA is one of the most popular methods to determine credit scores. LDA categorises firms as either solvent or insolvent, based on several factors and weightings on those factors.

# Logistic Regression Models, Cluster Analysis, and Principal Component Analysis

## Logistic Regression Models
_LO 20j: Describe the application of logistic regression models to estimate default probability_

Logistic Regression Models (or LOGIT models) are statistical tools which are used to predict default. They usually have three elements: 

* Systematic Element - variables in the linear predictor
* Random Element - the target variable and its associated probability function
* Link Function - a function of the target variable mean that the model ties to the systematic component

Assume $$\pi$$ is the odds that a default happens. The link functon represents the logarithm of the ratio between the default probability and the probability that the firm continues to be a performing borrower (the ratio is known as the odds). The LOGIT equation is therefore: 

$$LOGIT(\pi_i) = log\frac{\pi_i}{1-\pi_i}$$

## Cluster Analysis and Principal Component Analysis
_LO 20k: Define and interpret cluster analysis and principal component analysis_

Cluster analysis seeks to group variables in similar groupings. Principal Component Analysis (PCA) involves transforming an original tabular data set into a derived tabular data set. Essentially PCA is another form of Factor Analysis (albeit meaningfully different). 

# Cash Flow Simulation Model, Heuristic and Numerical Approaches, and Applying Qualitative Information
*LO 20l: Describe the use of a cash flow simulation model in assigning rating and default probability and explain the limitations of the model*

Cash flow simulations involve modelling future cash flows to determine credit-worthiness in the event that certain financial indicators are meaningless (e.g. financial institutions). These models are expensive and complex, however. 

## Heuristic Approaches vs. Numerical Approaches
_LO 20m: Describe the application of heuristic approaches, numeric approaches and artificial neural networks in modelling default risk and deifne their strengths and weaknesses_

Heuristic Methods mirror human decision making processes. Trial by error is used to generate data/expectations rather than statistical modelling. Numerical methods however solely rely on using "trained" algorithms and statistical methods. Expert Systems and Decision Support Systems are other implementations (rudimentary implementations of AI) of data processing. 

Neural Networks arose from bioligical studies, and aim to emulate human brian behaviour. They are used when data quality is poor and when operating in a "fuzzy" environment. Unfortunately however Neural Nets are black boxes in terms of their logic. 

In terms of the ideal factors, heuristic and numerical methods are: 
* Objectivity and Homogeneity: entirely compliant
* Specificity: numerical is 75% compliant and heuristic is 50% compliant
* Measurability and Verifiability: numerical is 75% compliant and heuristic is 50% compliant

## Applying Qualitative Information
_LO 20n: Describe the role and management of qualitative information in assessing probability of default_

There are three groups of qualitative information which encapsulate qualitative information: 
* Investment, innovation and technology
* Human resource management, motivation, retention of key resources, and maximising talent
* Effective and efficient internal processes
